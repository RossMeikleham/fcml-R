```{r setup, include=FALSE}
knitr::opts_chunk$set(cache=TRUE)
```

<h3>Linear regression</h3>
<p>We start by loading the Olympic 100m men's data</p>

```{r}
data <- read.csv("../../data/olympic100m.txt", header=FALSE)
x <- data$V1
t <- data$V2
```
<h4>Plotting</h4>
<p>It's useful to start with a plot</p>

```{r plot, fig.width=5, fig.height=5, message=FALSE}
plot(data.frame(x, t), col="red", pch=16)
```





<h4>Minismising the loss</h4>
<p>Recall that the total loss was given by:</p>
$$ L = \frac{1}{N}\sum_{n=1}^N (t_n - w_0 - w_1x_n)^2 $$
and the quantities that minimised it by:
$$ w_1 = \frac{\bar{x}\bar{t} - \bar{xt}}{\bar{x}\bar{x} - \bar{x^2}} $$
and
$$ w_0 = \bar{t} - w_1\bar{x} $$
where $\bar{z} = \frac{1}{N}\sum_{n=1}^N z_n$

```{r, results="hold"}
xbar  <- mean(x)
tbar  <- mean(t)
xxbar <- mean(x * x)
xtbar <- mean(x * t)
print(xbar)
print(tbar)
print(xxbar)
print(xtbar)
```

```{r, results="hold"}
w1 <- (tbar * xbar - xtbar)/(xbar * xbar - xxbar)
w0 <- tbar - w1 * xbar
print(w0)
print(w1)
```


<h4>Plotting</h4>
<p>We can now plot the fitted model</p>

```{r, fig.width=5, fig.height=5, message=FALSE}
x_test <- seq(1896, 2008, length=100)
f_test <- w0 + w1 * x_test
plot(data.frame(x, t), col="red", pch=16, 
     xlab="Olympic Year", ylab="Winning time (s)")
lines(x_test, f_test, col="blue")
```


<h4>Predictions</h4>
<p>We can now compute the prediction at 2012:</p>

```{r}
win_2012 <- w0 + w1 * 2012
print(win_2012)
```

<h4>Matrix and vector form</h4>
<p>We first defined $\mathbf{w},\mathbf{x}_n$ as:</p>
$$ \mathbf{w} = \left[\begin{array}{c} w_0\\w_1\end{array}\right],~~\mathbf{x}_n
= \left[\begin{array}{c} 1 \\ x_n \end{array}\right] $$
and:
$$ \mathbf{t} = \left[\begin{array}{c} t_1\\ t_2\\ \vdots\\ t_N
\end{array}\right]$$
and:
$$ \mathbf{X} = \left[\begin{array}{c} \mathbf{x}_1^T \\ \mathbf{x}_2^T \\
\vdots \\ \mathbf{x}_N^T \end{array}\right] = \left[ \begin{array}{cc} 1 & x_1
\\ 1 & x_2 \\ \vdots \\ 1 & x_N \end{array}\right] $$
The optimal value of $\mathbf{w}$ is then given by:
$$ \mathbf{w} = \left(\mathbf{X}^T\mathbf{X}\right)^{-1}\mathbf{X}^T\mathbf{t}
$$

```{r}
X <- cbind((rep(1, length(x))), x)
w <- solve(t(X) %*% X, t(X) %*% t)
print(w)
```

```{r, fig.width=5, fig.height=5, message=FALSE}
f_test <- w[1,] + w[2,] * x_test
plot(data.frame(x, t), col="red", pch=16,
     xlab="Olympic Year", ylab="Winning time (s)")
lines(x_test, f_test, col="blue")
```


<h4>Solving linear systems</h4>
<p>To obtain the optimal value of $\mathbf{w}$ we re-arranged:
$$ \mathbf{X}^T\mathbf{X}\mathbf{w} = \mathbf{X}^T\mathbf{t} $$
It is actually more efficient to solve this equation than explicitly inverting
$\mathbf{X}^T\mathbf{X}$.</p>
<p>To do this we can use `solve` which solves equations of the form
$\mathbf{A}\mathbf{z} = \mathbf{B}$ for $\mathbf{z}$.</p>

```{r}
w <- solve(t(X) %*% X, t(X) %*% t)
print(w)
```


<h4>Predicting in vector and matrix notation</h4>
<p>If we construct a test $\mathbf{X}$ object in the same format as $\mathbf{X}$
(we'll call it $\mathbf{X}_{*}$), we can obtain predictions via
$\mathbf{X}^*\mathbf{w}$.

```{r, fig.width=5, fig.height=5, message=FALSE}
X_test <- cbind((rep(1, length(x_test))), x_test)
f_test <- X_test %*% w
plot(data.frame(x, t), col="red", pch=16,
     xlab="Olympic Year", ylab="Winning time (s)")
lines(x_test, f_test, col="blue")
```


<p>Or we can make an $\mathbf{x}_{2012}$ object as:
$$ \mathbf{x}_{2012} = \left[\begin{array}{c} 1 \\ 2012 \end{array}\right] $$
and compute the prediction at 2012 as $\mathbf{w}^T\mathbf{x}_{2012}$.</p>

```{r}
x_2012 <- c(1, 2012)
f_2012 <- t(w) %*% x_2012
print(f_2012)
```
